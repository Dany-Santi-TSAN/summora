"""
Analyseur audio sp√©cialis√© pour les meetings
Analyse des propri√©t√©s audio avec focus sur la qualit√© meeting
"""
import os
from pathlib import Path
from typing import Optional, Union, Dict
import logging
from dataclasses import dataclass

import numpy as np
import librosa
import matplotlib.pyplot as plt
import librosa.display

from .utils import validate_audio_path, format_duration

logger = logging.getLogger(__name__)

# === Configuration de l'analyseur audio sp√©cifique au r√©union ===

@dataclass
class MeetingAudioConfig:
    """
    Configuration pour l‚Äôanalyse des r√©unions audio.
    Adapt√© aux besoins sp√©cifiques des √©changes humains en contexte professionnel.

    """
    frame_length: int = 2048
    hop_length: int = 512
    n_mfcc: int = 13 # Standard th√©orique
    silence_percentile: float = 15.0 # Seuil adaptatif
    generate_plots: bool = True
    plot_figsize: tuple = (15, 10)

    # Seuils sp√©cifiques aux meetings
    min_meeting_duration: float = 60.0   # 1 minute minimum
    optimal_speech_ratio: float = 0.65   # 65% de parole id√©al
    max_silence_gap: float = 10.0        # Silence > 10s = probl√®me

class MeetingAudioAnalyzer:
    """
    Analyseur d√©di√© aux fichiers audio de r√©unions professionnelles.
    Fournit des m√©triques utiles et des recommandations pratiques.
    """

    def __init__(self, config: Optional[MeetingAudioConfig] = None):
        """
        Initialise l'analyseur audio pour meetings.

        Args:
            config: Configuration d'analyse (utilise les d√©fauts si None)
        """
        self.config = config or MeetingAudioConfig()

    # === Calcul des scores de qualit√© de r√©union ===

    def _calculate_meeting_quality_score(self, sr: int, duration: float,
                                       speech_ratio: float, dynamic_range_db: float) -> tuple:
        """
        Calcule un score de qualit√© sp√©cifique aux meetings.

        Args:
            sr: Sample rate
            duration: Dur√©e en secondes
            speech_ratio: Ratio de parole (0-1)
            dynamic_range_db: Dynamic range en dB

        Retourne:
            tuple: (score, grade, statuses, recommendations)
        """
        score = 0
        statuses = {}
        recommendations = []

        # √âvaluation sample rate pour meetings (8kHz-48kHz)
        if 16000 <= sr <= 48000:
            score += 25
            statuses['sample_rate'] = "‚úÖ Qualit√© optimale pour meeting"
        elif 8000 <= sr < 16000:
            score += 15
            statuses['sample_rate'] = "‚ö†Ô∏è Qualit√© acceptable mais am√©liorable"
            recommendations.append("Enregistrer en 16kHz minimum pour meilleure qualit√©")
        else:
            statuses['sample_rate'] = "‚ùå Qualit√© insuffisante pour meeting"
            recommendations.append("Utiliser un sample rate entre 16-48kHz")

        # √âvaluation dur√©e meeting
        if duration >= self.config.min_meeting_duration:
            score += 25
            if duration <= 3600:  # <= 1h
                statuses['duration'] = f"‚úÖ Dur√©e appropri√©e ({format_duration(duration)})"
            else:
                statuses['duration'] = f"‚ö†Ô∏è Meeting long ({format_duration(duration)}) - v√©rifier efficacit√©"
                recommendations.append("Meetings > 1h peuvent √™tre moins efficaces")
        else:
            statuses['duration'] = f"‚ö†Ô∏è Meeting tr√®s court ({format_duration(duration)})"
            recommendations.append("Meetings < 1min peu adapt√©s √† l'analyse")

        # √âvaluation ratio de parole pour meetings
        if 0.55 <= speech_ratio <= 0.75:
            score += 25
            statuses['speech_ratio'] = f"‚úÖ Ratio parole optimal ({speech_ratio*100:.1f}%)"
        elif 0.4 <= speech_ratio < 0.55:
            score += 15
            statuses['speech_ratio'] = f"‚ö†Ô∏è Peu de parole ({speech_ratio*100:.1f}%)"
            recommendations.append("Meeting silencieux - v√©rifier engagement participants")
        elif speech_ratio > 0.8:
            score += 10
            statuses['speech_ratio'] = f"‚ö†Ô∏è Beaucoup de parole ({speech_ratio*100:.1f}%)"
            recommendations.append("Meeting dense - pr√©voir des pauses")
        else:
            statuses['speech_ratio'] = f"‚ùå Trop de silence ({speech_ratio*100:.1f}%)"
            recommendations.append("Meeting peu productif - revoir animation")

        # √âvaluation dynamic range pour meetings
        if 15 <= dynamic_range_db <= 50:
            score += 25
            statuses['dynamic_range'] = "‚úÖ Qualit√© audio claire"
        elif dynamic_range_db < 10:
            score += 5
            statuses['dynamic_range'] = "‚ùå Audio compress√© ou faible"
            recommendations.append("Am√©liorer setup micro pour meetings futurs")
        else:
            score += 15
            statuses['dynamic_range'] = "‚ö†Ô∏è Audio avec variations importantes"
            recommendations.append("V√©rifier distance micro et acoustique salle")

        # Calcul du grade meeting-specific
        if score >= 85:
            grade = "A+"
        elif score >= 75:
            grade = "A"
        elif score >= 65:
            grade = "B"
        elif score >= 50:
            grade = "C"
        else:
            grade = "D"

        return score, grade, statuses, recommendations

    # === G√©n√©ration des visualisations audio ===

    """
    Les visualisations aident √† comprendre la dynamique de la r√©union :
    - les moments o√π les participants parlent le plus
    - les p√©riodes de silence
    - l'√©nergie globale de la discussion.

    Cela peut aider √† identifier les r√©unions productives et celles qui n√©cessitent des am√©liorations.

    La fonction peut √©galement aider √† diagnostiquer des probl√®mes techniques dans les enregistrements audio.
    """


    def _generate_meeting_visualizations(self, y: np.ndarray, sr: int,
                                       duration: float, audio_path: str) -> None:
            """
            G√©n√®re des visualisations optimis√©es pour l'analyse de meetings :

            1. Timeline audio avec d√©tection des moments parl√©s (zones orang√©es)
            2. Spectrogramme centr√© sur la bande voix humaine (200‚Äì4000Hz)
            3. Histogramme silence vs parole ‚Äì indicateur de dynamique
            4. Suivi RMS (Root Mean Square) pour d√©tecter les pics d‚Äôactivit√©

            Args:
                y: Signal audio
                sr: Sample rate
                duration: Dur√©e
                audio_path: Chemin du fichier pour le titre
            """
            if not self.config.generate_plots:
                return

            try:
                fig, axes = plt.subplots(2, 2, figsize=self.config.plot_figsize)
                fig.suptitle(f'üìä Analyse Meeting Audio - {os.path.basename(audio_path)}'
                            ,fontsize=16, fontweight='bold')

                # 1. Timeline audio avec zones de parole
                time = np.linspace(0, duration, len(y))
                axes[0, 0].plot(time, y, linewidth=0.6, color='steelblue', alpha=0.7)

                # Highlight des zones de forte activit√© (parole probable)
                rms = librosa.feature.rms(y=y, frame_length=self.config.frame_length
                                        ,hop_length=self.config.hop_length)[0]
                time_rms = librosa.frames_to_time(np.arange(len(rms)), sr=sr
                                                ,hop_length=self.config.hop_length)
                speech_threshold = np.percentile(rms, 70)
                speech_zones = rms > speech_threshold

                for i in range(len(time_rms)-1):
                    if speech_zones[i]:
                        axes[0, 0].axvspan(time_rms[i], time_rms[i+1], alpha=0.3, color='orange')

                axes[0, 0].set_title('üé§ Timeline Meeting avec zones de parole')
                axes[0, 0].set_xlabel('Temps (minutes)')
                axes[0, 0].set_ylabel('Amplitude')
                axes[0, 0].grid(True, alpha=0.3)

                # Conversion temps en minutes pour meeting
                time_minutes = time / 60
                axes[0, 0].set_xlim(0, duration/60)

                # 2. Spectrogramme avec focus voix humaine (200-4000Hz)
                D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
                img = librosa.display.specshow(D, y_axis='hz', x_axis='time'
                                            ,sr=sr, ax=axes[0, 1], cmap='viridis'
                                            ,fmax=4000)  # Focus fr√©quences voix
                axes[0, 1].set_title('üéµ Spectrogramme (focus voix humaine)')
                plt.colorbar(img, ax=axes[0, 1], format='%+2.0f dB')

                # 3. Analyse des silences et activit√©
                silence_threshold = np.percentile(np.abs(y), self.config.silence_percentile)
                is_silence = np.abs(y) < silence_threshold

                # Histogramme silence vs parole
                categories = ['Silence', 'Parole']
                values = [np.mean(is_silence), 1 - np.mean(is_silence)]
                colors = ['lightcoral', 'lightgreen']

                bars = axes[1, 0].bar(categories, values, color=colors, alpha=0.7)
                axes[1, 0].set_title('üìä R√©partition Silence / Parole')
                axes[1, 0].set_ylabel('Proportion')
                axes[1, 0].set_ylim(0, 1)

                # Ajout des pourcentages sur les barres
                for bar, value in zip(bars, values):
                    height = bar.get_height()
                    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01
                                ,f'{value*100:.1f}%', ha='center', va='bottom', fontweight='bold')

                # 4. √ânergie RMS avec seuils meeting
                axes[1, 1].plot(time_rms, rms, color='orange', linewidth=2, label='√ânergie RMS')
                axes[1, 1].axhline(y=speech_threshold, color='red', linestyle='--'
                                ,alpha=0.7, label='Seuil parole')
                axes[1, 1].fill_between(time_rms, rms, alpha=0.3, color='orange')
                axes[1, 1].set_title('‚ö° √ânergie Meeting (d√©tection activit√©)')
                axes[1, 1].set_xlabel('Temps (minutes)')
                axes[1, 1].set_ylabel('√ânergie RMS')
                axes[1, 1].legend()
                axes[1, 1].grid(True, alpha=0.3)

                plt.tight_layout()
                plt.show()

            except Exception as e:
                logger.warning(f"Erreur g√©n√©ration visualisations meeting: {e}")

    # === Fonction principale d'analyse audio de r√©union ===

    def analyze_meeting_audio_property(self, audio_path: Union[str, Path]) -> Dict:
        """
        Analyse compl√®te d'un audio de r√©union

        Pipeline de traitement :
        1. üìÇ Validation et chargement du fichier (avec son sample rate natif)
        2. üìä Extraction des features cl√©s :
            - Dur√©e, Speech/Silence Ratio
            - Plage dynamique (dB)
            - MFCCs (vecteurs vocaux)
            - ZCR (clart√© vocale)
        3. üí° Scoring & recommandations via `_calculate_meeting_quality_score`
        4. üìâ Visualisation (optionnelle)

        Args:
            audio_path: Chemin vers le fichier audio

        Retourne:
            Dict: Propri√©t√©s audio et m√©triques sp√©cifiques aux meetings
        """
        audio_path = Path(audio_path)

        try:
            logger.info(f"üé§ Analyse audio meeting: {audio_path.name}")

            # Validation et chargement
            validated_path = validate_audio_path(audio_path)
            if not validated_path:
                return {"error": "file_validation_failed", "path": str(audio_path)}

            # Chargement avec sample rate original
            y, sr = librosa.load(str(validated_path), sr=None)
            duration = len(y) / sr

            logger.info(f"üìà Propri√©t√©s: {sr}Hz, {format_duration(duration)}")

            # G√©n√©ration des visualisations meeting
            logger.info("üé® G√©n√©ration visualisations meeting...")
            self._generate_meeting_visualizations(y, sr, duration, str(audio_path))

            # Calculs des m√©triques meeting
            logger.info("üî¢ Calcul m√©triques meeting...")

            # D√©tection de silence adaptatif
            silence_threshold = np.percentile(np.abs(y), self.config.silence_percentile)
            silence_ratio = np.mean(np.abs(y) < silence_threshold)
            speech_ratio = 1 - silence_ratio

            # Dynamic Range
            max_amp = np.max(np.abs(y))
            mean_amp = np.mean(np.abs(y))
            dynamic_range_db = 20 * np.log10(max_amp / (mean_amp + 1e-8))

            # Zero Crossing Rate (indicateur de clart√© vocale)
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            mean_zcr = np.mean(zcr)

            # MFCC pour analyse vocale meeting
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.config.n_mfcc)
            mfcc_mean = np.mean(mfccs, axis=1)

            # Score de qualit√© meeting
            meeting_score, meeting_grade, meeting_statuses, recommendations = \
                self._calculate_meeting_quality_score(sr, duration, speech_ratio, dynamic_range_db)

            # Affichage des r√©sultats
            logger.info(f"üìä M√©triques meeting:")
            logger.info(f"   ‚Ä¢ Ratio parole: {speech_ratio*100:.1f}%")
            logger.info(f"   ‚Ä¢ Score qualit√©: {meeting_score}/100 (Grade {meeting_grade})")
            for status in meeting_statuses.values():
                logger.info(f"   ‚Ä¢ {status}")

            return {
                # Propri√©t√©s de base
                "duration": float(duration)
                ,"duration_formatted": format_duration(duration)
                ,"sample_rate": int(sr)
                ,"samples_count": int(len(y))

                # M√©triques d'amplitude
                ,"max_amplitude": float(max_amp)
                ,"rms_energy": float(np.sqrt(np.mean(y**2)))
                ,"mean_amplitude": float(mean_amp)

                # M√©triques meeting sp√©cifiques
                ,"silence_ratio": float(silence_ratio)
                ,"speech_ratio": float(speech_ratio)
                ,"dynamic_range_db": float(dynamic_range_db)
                ,"zero_crossing_rate": float(mean_zcr)

                # Score qualit√© meeting
                ,"meeting_quality_score": int(meeting_score)
                ,"meeting_quality_grade": meeting_grade
                ,"meeting_status": meeting_statuses
                ,"recommendations": recommendations

                # Analyse vocale optimis√©e meeting
                ,"mfcc_coefficients": [float(x) for x in mfcc_mean[:5]]
                ,"vocal_clarity_score": float(1.0 / (1.0 + mean_zcr * 10))  # Score clart√©

                # M√©tadonn√©es
                ,"analysis_method": "librosa + meeting_optimization"
                ,"optimized_for": "meeting_analysis"
                ,"config_used": {
                    "silence_percentile": self.config.silence_percentile,
                    "min_duration": self.config.min_meeting_duration
                    }
                }

        except Exception as e:
            logger.error(f"‚ùå Erreur analyse audio meeting: {e}")
            return {
                "error": str(e),
                "error_type": "meeting_audio_analysis_failure",
                "suggestion": "V√©rifiez le format audio et la qualit√© d'enregistrement"
                }


# Factory function
def analyze_meeting_audio_file(audio_path: Union[str, Path],
                         generate_plots: bool = True,
                         **config_kwargs) -> Dict:
    """
    Helper function pour analyse rapide d'un audio de meeting.

    Args:
        audio_path: Chemin vers le fichier audio
        generate_plots: G√©n√©rer les visualisations
        **config_kwargs: Param√®tres de configuration

    Retourne:
        Dict: R√©sultats d'analyse audio meeting
    """
    config = MeetingAudioConfig(generate_plots=generate_plots, **config_kwargs)
    analyzer = MeetingAudioAnalyzer(config)
    return analyzer.analyze_meeting_audio(audio_path)
